{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subsetting, Anomalies, and Climatologies\n",
    "\n",
    "In a previous notebook (`Reanalysis`) we created a relatively large database of raw $U,V,\\psi$.\n",
    "This is helpful, but for our visualizations it's nice to sub-set the data in advance so that all we have to do is load the relevant bits.\n",
    "We'll also pre-compute anomalies and climatologies, which saves substantial computational time down the road at the expense of a bit of file storage.\n",
    "Because we don't need the fine time resolution, we'll also re-sample everything to a daily time step (note that we didn't just download daily reanalysis data because we need to shift the end-of-day time!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import glob\n",
    "from paraguayfloodspy.xrutil import *\n",
    "from paraguayfloodspy.pars import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clim_plot': {'latmax': 10, 'latmin': -55, 'lonmax': 360, 'lonmin': 240},\n",
       " 'months': [11, 12, 1, 2],\n",
       " 'rain': {'latmax': 10, 'latmin': -55, 'lonmax': 330, 'lonmin': 270},\n",
       " 'rpy_rain': {'latmax': -22.75,\n",
       "  'latmin': -26.75,\n",
       "  'lonmax': 304.75,\n",
       "  'lonmin': 301.25},\n",
       " 'time': {'eyear': 2016, 'syear': 1979},\n",
       " 'wt_rgn': {'latmax': -15, 'latmin': -30, 'lonmax': 315, 'lonmin': 295}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pars = GetPars('all')\n",
    "pars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reanalysis Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define a transfer function.\n",
    "This function needs to:\n",
    "1. Apply a time shift to the data to correct for the end-of-day difference between reanalysis and the CPC Rain data (see our paper for details)\n",
    "2. Re-sample data to **daily time step**\n",
    "3. Sub-set data to include only the desired months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transfer_fn(var, lonmin, lonmax, latmin, latmax, shift_time_h, return_daily, months):\n",
    "    var = var.sel(lon = slice(lonmin, lonmax), lat = slice(latmax, latmin))\n",
    "    # shift time by hours, if desired\n",
    "    if shift_time_h != 0:\n",
    "        time_old = var.time.values\n",
    "        time_new = time_old + np.timedelta64(12, 'h')\n",
    "        var['time'] = time_new\n",
    "    # resample to daily time step, if desired\n",
    "    if return_daily:\n",
    "        var = var.resample('1D', dim = 'time')\n",
    "    # subset months if required\n",
    "    if months is not None:\n",
    "        var = var.sel(time = np.in1d(var['time.month'], months))\n",
    "    return(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`read_netcdfs` needs this as a `lambda` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trans_lam = lambda ds: transfer_fn(\n",
    "    var=ds, \n",
    "    lonmin=pars['clim_plot']['lonmin'], \n",
    "    lonmax=pars['clim_plot']['lonmax'], \n",
    "    latmin=pars['clim_plot']['latmin'],\n",
    "    latmax=pars['clim_plot']['latmax'],\n",
    "    months=pars['months'],\n",
    "    shift_time_h=12, return_daily=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can go through and read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for var in ['uwnd', 'vwnd', 'streamfunc']:\n",
    "    for level_i in [200, 850]:\n",
    "        fnames = glob.glob('../_data/reanalysis/raw/{}_{}_*.nc'.format(var, level_i))\n",
    "        if len(fnames) > 0:\n",
    "            ds = read_netcdfs(fnames, dim='time', transform_func=trans_lam)\n",
    "            climatology, anomaly = CalcAnomaly(ds, ret_clim=True)\n",
    "            ds.to_netcdf(\"../_data/reanalysis/subset/{}_{}_raw.nc\".format(var, level_i))\n",
    "            anomaly.to_netcdf(\"../_data/reanalysis/subset/{}_{}_anom.nc\".format(var, level_i))\n",
    "            climatology.to_netcdf(\"../_data/reanalysis/subset/{}_{}_clim.nc\".format(var, level_i))\n",
    "        else:\n",
    "            print(\"No {} data at {}hPa\".format(var, level_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rainfall Data\n",
    "\n",
    "N.B: the rainfall data latiutde data is arranged slightly differently!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transfer_fn(var, lonmin, lonmax, latmin, latmax, months):\n",
    "    var = var.sel(lon = slice(lonmin, lonmax), lat = slice(latmin, latmax))\n",
    "    if months is not None:\n",
    "        var = var.sel(time = np.in1d(var['time.month'], months))\n",
    "    return(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trans_lam = lambda ds: transfer_fn(\n",
    "    var=ds, \n",
    "    lonmin=pars['rain']['lonmin'], \n",
    "    lonmax=pars['rain']['lonmax'], \n",
    "    latmin=pars['rain']['latmin'],\n",
    "    latmax=pars['rain']['latmax'],\n",
    "    months=pars['months']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fnames = glob.glob('../_data/rainfall/raw/*.nc')\n",
    "if len(fnames) > 0:\n",
    "    ds = read_netcdfs(fnames, dim='time', transform_func=trans_lam)\n",
    "    climatology, anomaly = CalcAnomaly(ds, ret_clim=True)\n",
    "    ds.to_netcdf(\"../_data/rainfall/subset/cpc_raw.nc\")\n",
    "    anomaly.to_netcdf(\"../_data/rainfall/subset/cpc_anom.nc\")\n",
    "    climatology.to_netcdf(\"../_data/rainfall/subset/cpc_clim.nc\")\n",
    "else:\n",
    "    print(\"No rainfall data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
